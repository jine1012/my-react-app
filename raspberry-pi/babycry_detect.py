#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì•„ê¸° ìš¸ìŒ ê°ì§€ ì‹œìŠ¤í…œ
ì‹¤ì‹œê°„ ë§ˆì´í¬ ì…ë ¥ì„ í†µí•´ ì•„ê¸° ìš¸ìŒì„ ê°ì§€í•˜ê³  Node.js ì„œë²„ë¡œ ì´ë²¤íŠ¸ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python babycry_detect.py                    # ê¸°ë³¸ ê°ì§€ ëª¨ë“œ
    python babycry_detect.py --save-audio       # ì˜¤ë””ì˜¤ ì €ì¥ ëª¨ë“œ
    python babycry_detect.py --mode test        # ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ëª¨ë“œ
"""

import numpy as np
import pyaudio
import threading
import queue
import time
import json
import requests
import argparse
import os
import wave
import subprocess
from datetime import datetime
from typing import Optional, Tuple, Any
import signal
import sys

try:
    import librosa
    HAS_LIBROSA = True
except ImportError:
    print("âš ï¸ librosaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    print("ì„¤ì¹˜ ë°©ë²•: pip install librosa")
    HAS_LIBROSA = False

try:
    import tensorflow as tf
    HAS_TENSORFLOW = True
except ImportError:
    print("âš ï¸ TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    print("ì„¤ì¹˜ ë°©ë²•: pip install tensorflow")
    HAS_TENSORFLOW = False


class BabyCryDetector:
    """
    ì•„ê¸° ìš¸ìŒ ê°ì§€ ì‹œìŠ¤í…œ
    
    ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ë¶„ì„í•˜ì—¬ ì•„ê¸° ìš¸ìŒì„ ê°ì§€í•˜ê³ ,
    ê°ì§€ ê²°ê³¼ë¥¼ Node.js ì„œë²„ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, 
                 confidence_threshold: float = 0.8,
                 nodejs_server: str = 'http://192.168.0.4:5000',
                 save_audio: bool = False,
                 sample_rate: int = 16000,
                 chunk_size: int = 8192):
        """
        ê°ì§€ê¸° ì´ˆê¸°í™”
        
        Args:
            confidence_threshold: ê°ì§€ ì‹ ë¢°ë„ ì„ê³„ê°’ (0.0-1.0)
            nodejs_server: Node.js ì„œë²„ URL
            save_audio: ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ì—¬ë¶€
            sample_rate: ì˜¤ë””ì˜¤ ìƒ˜í”Œë§ ë ˆì´íŠ¸
            chunk_size: ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì²­í¬ í¬ê¸°
        """
        self.confidence_threshold = confidence_threshold
        self.nodejs_server = nodejs_server
        self.save_audio = save_audio
        self.sample_rate = sample_rate
        self.chunk_size = chunk_size
        
        # ì˜¤ë””ì˜¤ ê´€ë ¨ ë³€ìˆ˜
        self.audio = pyaudio.PyAudio()
        self.stream = None
        self.audio_queue = queue.Queue(maxsize=50)
        self.is_running = False
        
        # ML ëª¨ë¸ (ìˆëŠ” ê²½ìš°)
        self.model = None
        
        # ì˜¤ë””ì˜¤ ì €ì¥ ì„¤ì •
        self.audio_save_path = "recorded_audio"
        if self.save_audio:
            self._setup_audio_directories()
        
        # ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ì„¤ì •
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        print(f"ğŸ™ï¸ ì•„ê¸° ìš¸ìŒ ê°ì§€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print(f"   - ì‹ ë¢°ë„ ì„ê³„ê°’: {confidence_threshold}")
        print(f"   - Node.js ì„œë²„: {nodejs_server}")
        print(f"   - ì˜¤ë””ì˜¤ ì €ì¥: {'í™œì„±í™”' if save_audio else 'ë¹„í™œì„±í™”'}")
        print(f"   - ìƒ˜í”Œë§ ë ˆì´íŠ¸: {sample_rate}Hz")
        
        # ML ëª¨ë¸ ë¡œë“œ ì‹œë„
        self._load_model()
    
    def _setup_audio_directories(self) -> None:
        """ì˜¤ë””ì˜¤ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •"""
        try:
            os.makedirs(self.audio_save_path, exist_ok=True)
            os.makedirs(f"{self.audio_save_path}/detections", exist_ok=True)
            os.makedirs(f"{self.audio_save_path}/continuous", exist_ok=True)
            print(f"ğŸ“ ì˜¤ë””ì˜¤ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±: {self.audio_save_path}")
        except Exception as e:
            print(f"âŒ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
            self.save_audio = False
    
    def _signal_handler(self, signum, frame):
        """ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ (Ctrl+C ë“±)"""
        print(f"\nğŸ“¡ ì‹œê·¸ë„ {signum} ìˆ˜ì‹ ë¨. ì •ë¦¬ ì¤‘...")
        self.stop_detection()
        sys.exit(0)
    
    def _load_model(self) -> None:
        """ML ëª¨ë¸ ë¡œë“œ"""
        try:
            # ëª¨ë¸ íŒŒì¼ì´ ìˆëŠ” ê²½ìš° ë¡œë“œ
            model_path = "models/baby_cry_model.h5"
            if os.path.exists(model_path) and HAS_TENSORFLOW:
                self.model = tf.keras.models.load_model(model_path)
                print(f"âœ… ML ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_path}")
            else:
                print("ğŸ“ ML ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
                self.model = None
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ“ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            self.model = None
    
    def save_audio_chunk(self, audio_data: np.ndarray, detection_result: bool = False) -> Optional[str]:
        """
        ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ WAV íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            audio_data: ì €ì¥í•  ì˜¤ë””ì˜¤ ë°ì´í„°
            detection_result: ìš¸ìŒì´ ê°ì§€ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
        """
        if not self.save_audio:
            return None
        
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
            
            if detection_result:
                # ìš¸ìŒì´ ê°ì§€ëœ ê²½ìš° íŠ¹ë³„ í´ë”ì— ì €ì¥
                filename = f"{self.audio_save_path}/detections/cry_detected_{timestamp}.wav"
            else:
                # ì¼ë°˜ ì˜¤ë””ì˜¤ëŠ” ì—°ì† ë…¹ìŒ í´ë”ì— ì €ì¥
                filename = f"{self.audio_save_path}/continuous/audio_{timestamp}.wav"
            
            # WAV íŒŒì¼ë¡œ ì €ì¥
            with wave.open(filename, 'wb') as wav_file:
                wav_file.setnchannels(1)  # ëª¨ë…¸
                wav_file.setsampwidth(4)  # 32-bit floatë¥¼ ìœ„í•´ 4ë°”ì´íŠ¸
                wav_file.setframerate(self.sample_rate)
                
                # float32ë¥¼ int32ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
                audio_int = (audio_data * 2147483647).astype(np.int32)
                wav_file.writeframes(audio_int.tobytes())
            
            print(f"ğŸ’¾ ì˜¤ë””ì˜¤ ì €ì¥: {filename}")
            return filename
            
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    def audio_callback(self, in_data, frame_count, time_info, status):
        """
        ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì§‘ ì½œë°±
        """
        if status:
            print(f"âš ï¸ ì˜¤ë””ì˜¤ ìƒíƒœ ê²½ê³ : {status}")
        
        # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ íì— ì¶”ê°€
        audio_data = np.frombuffer(in_data, dtype=np.float32)
        
        if not self.audio_queue.full():
            self.audio_queue.put(audio_data)
        
        return (in_data, pyaudio.paContinue)
    
    def extract_features(self, audio_data: np.ndarray) -> Optional[np.ndarray]:
        """
        ì˜¤ë””ì˜¤ì—ì„œ íŠ¹ì§• ì¶”ì¶œ (MFCC, ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë“±)
        
        Args:
            audio_data: ì…ë ¥ ì˜¤ë””ì˜¤ ë°ì´í„°
            
        Returns:
            ì¶”ì¶œëœ íŠ¹ì§• ë²¡í„° ë˜ëŠ” None
        """
        try:
            if not HAS_LIBROSA:
                # librosaê°€ ì—†ëŠ” ê²½ìš° ê°„ë‹¨í•œ íŠ¹ì§• ì‚¬ìš©
                features = np.array([
                    np.mean(audio_data),  # í‰ê· 
                    np.std(audio_data),   # í‘œì¤€í¸ì°¨
                    np.max(audio_data),   # ìµœëŒ€ê°’
                    np.min(audio_data),   # ìµœì†Œê°’
                    np.mean(np.abs(audio_data))  # ì ˆëŒ€ê°’ í‰ê· 
                ])
                return features.reshape(1, -1)
            
            # MFCC íŠ¹ì§• ì¶”ì¶œ
            mfccs = librosa.feature.mfcc(
                y=audio_data, 
                sr=self.sample_rate, 
                n_mfcc=13
            )
            
            # ì¶”ê°€ íŠ¹ì§•ë“¤
            spectral_centroid = librosa.feature.spectral_centroid(
                y=audio_data, 
                sr=self.sample_rate
            )
            
            zero_crossing_rate = librosa.feature.zero_crossing_rate(audio_data)
            
            # íŠ¹ì§• ë²¡í„° ê²°í•©
            features = np.concatenate([
                np.mean(mfccs, axis=1),
                np.mean(spectral_centroid),
                np.mean(zero_crossing_rate)
            ])
            
            return features.reshape(1, -1)
            
        except Exception as e:
            print(f"âŒ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def predict_cry(self, features: np.ndarray) -> Tuple[bool, float]:
        """
        íŠ¹ì§• ë²¡í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìš¸ìŒ ì˜ˆì¸¡
        
        Args:
            features: ì…ë ¥ íŠ¹ì§• ë²¡í„°
            
        Returns:
            (ìš¸ìŒ ì—¬ë¶€, ì‹ ë¢°ë„)
        """
        if self.model is None:
            # ì‹œë®¬ë ˆì´ì…˜: ì˜¤ë””ì˜¤ ë ˆë²¨ ê¸°ë°˜ ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±
            import random
            
            # ì˜¤ë””ì˜¤ ë ˆë²¨ ê¸°ë°˜ ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±
            if len(features.shape) > 1:
                audio_level = np.mean(np.abs(features))
            else:
                audio_level = np.mean(np.abs(features))
            
            if audio_level > 0.1:  # ì¼ì • ë³¼ë¥¨ ì´ìƒ
                confidence = random.uniform(0.6, 0.95)
                is_cry = confidence > self.confidence_threshold
            else:
                confidence = random.uniform(0.1, 0.4)
                is_cry = False
            
            return is_cry, confidence
        
        else:
            # ì‹¤ì œ ëª¨ë¸ ì˜ˆì¸¡
            try:
                prediction = self.model.predict(features)[0]
                confidence = float(prediction[0])
                is_cry = confidence > self.confidence_threshold
                
                return is_cry, confidence
                
            except Exception as e:
                print(f"âŒ ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                return False, 0.0
    
    def send_detection_event(self, confidence: float, audio_features: Optional[np.ndarray] = None, audio_file_path: Optional[str] = None) -> bool:
        """
        Node.js ì„œë²„ë¡œ ê°ì§€ ì´ë²¤íŠ¸ ì „ì†¡
        
        Args:
            confidence: ê°ì§€ ì‹ ë¢°ë„
            audio_features: ì˜¤ë””ì˜¤ íŠ¹ì§• (ì„ íƒì‚¬í•­)
            audio_file_path: ì €ì¥ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            
        Returns:
            ì „ì†¡ ì„±ê³µ ì—¬ë¶€
        """
        try:
            event_data = {
                'timestamp': datetime.now().isoformat(),
                'confidence': round(confidence * 100, 2),  # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜
                'source': 'babycry_detect.py',
                'audio_features': audio_features.tolist() if audio_features is not None else None,
                'audio_file_path': audio_file_path  # ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ì¶”ê°€
            }
            
            response = requests.post(
                f'{self.nodejs_server}/api/cry-detection/detection-event',
                json=event_data,
                timeout=5
            )
            
            if response.status_code == 200:
                print(f"âœ… ê°ì§€ ì´ë²¤íŠ¸ ì „ì†¡ ì„±ê³µ: {confidence*100:.1f}%")
                return True
            else:
                print(f"âš ï¸ ì´ë²¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨: HTTP {response.status_code}")
                return False
                
        except requests.exceptions.Timeout:
            print("âš ï¸ ì„œë²„ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼")
            return False
        except requests.exceptions.ConnectionError:
            print("âš ï¸ ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
            return False
        except Exception as e:
            print(f"âŒ ì´ë²¤íŠ¸ ì „ì†¡ ì˜¤ë¥˜: {e}")
            return False
    
    def log_detection(self, confidence: float, audio_file_path: Optional[str] = None) -> None:
        """
        ê°ì§€ ì´ë²¤íŠ¸ë¥¼ ë¡œì»¬ íŒŒì¼ì— ê¸°ë¡
        
        Args:
            confidence: ê°ì§€ ì‹ ë¢°ë„
            audio_file_path: ì €ì¥ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
        """
        try:
            log_entry = {
                'timestamp': datetime.now().isoformat(),
                'confidence': confidence,
                'type': 'baby_cry_detected',
                'audio_file': audio_file_path
            }
            
            with open('detection_log.json', 'a') as f:
                f.write(json.dumps(log_entry) + '\n')
                
        except Exception as e:
            print(f"âš ï¸ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def process_audio_chunk(self, audio_data: np.ndarray) -> None:
        """
        ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ ì²˜ë¦¬í•˜ì—¬ ìš¸ìŒ ê°ì§€
        
        Args:
            audio_data: ì²˜ë¦¬í•  ì˜¤ë””ì˜¤ ë°ì´í„°
        """
        try:
            # íŠ¹ì§• ì¶”ì¶œ
            features = self.extract_features(audio_data)
            if features is None:
                return
            
            # ìš¸ìŒ ì˜ˆì¸¡
            is_cry, confidence = self.predict_cry(features)
            
            # í˜„ì¬ ì‹œê°„
            current_time = datetime.now().strftime("%H:%M:%S")
            
            # ì˜¤ë””ì˜¤ ì €ì¥ (ìš¸ìŒ ê°ì§€ëœ ê²½ìš° íŠ¹ë³„ ì €ì¥)
            saved_file = None
            if self.save_audio:
                if is_cry:
                    saved_file = self.save_audio_chunk(audio_data, detection_result=True)
                elif int(time.time()) % 60 == 0:  # 1ë¶„ë§ˆë‹¤ ì¼ë°˜ ì˜¤ë””ì˜¤ë„ ì €ì¥
                    saved_file = self.save_audio_chunk(audio_data, detection_result=False)
            
            if is_cry:
                print(f"ğŸ”” [{current_time}] ì•„ê¸° ìš¸ìŒ ê°ì§€! (ì‹ ë¢°ë„: {confidence*100:.1f}%)")
                if saved_file:
                    print(f"   ğŸ“ ì €ì¥ë¨: {saved_file}")
                
                # Node.js ì„œë²„ë¡œ ì´ë²¤íŠ¸ ì „ì†¡ (íŒŒì¼ ê²½ë¡œ í¬í•¨)
                self.send_detection_event(confidence, features, saved_file)
                
                # ë¡œì»¬ ë¡œê·¸ ì €ì¥ (íŒŒì¼ ê²½ë¡œ í¬í•¨)
                self.log_detection(confidence, saved_file)
                
            else:
                # ë‚®ì€ ë¹ˆë„ë¡œ ì •ìƒ ìƒíƒœ ë¡œê¹…
                if int(time.time()) % 30 == 0:  # 30ì´ˆë§ˆë‹¤
                    print(f"ğŸ”‡ [{current_time}] ì •ìƒ ìƒíƒœ (ì‹ ë¢°ë„: {confidence*100:.1f}%)")
        
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    def start_detection(self) -> None:
        """
        ìš¸ìŒ ê°ì§€ ì‹œì‘
        """
        try:
            print("ğŸš€ ìš¸ìŒ ê°ì§€ ì‹œì‘...")
            
            # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
            self.stream = self.audio.open(
                format=pyaudio.paFloat32,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=1024,
                stream_callback=self.audio_callback
            )
            
            self.stream.start_stream()
            self.is_running = True
            
            print(f"ğŸ™ï¸ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ë¨ (ìƒ˜í”Œë§: {self.sample_rate}Hz)")
            print("ğŸ”„ ìš¸ìŒ ê°ì§€ ì¤‘... (Ctrl+Cë¡œ ì¤‘ì§€)")
            
            # ë©”ì¸ ì²˜ë¦¬ ë£¨í”„
            audio_buffer = []
            
            while self.is_running:
                try:
                    # íì—ì„œ ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    if not self.audio_queue.empty():
                        chunk = self.audio_queue.get(timeout=1)
                        audio_buffer.extend(chunk)
                        
                        # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ëª¨ì´ë©´ ì²˜ë¦¬
                        if len(audio_buffer) >= self.chunk_size:
                            audio_data = np.array(audio_buffer[:self.chunk_size])
                            audio_buffer = audio_buffer[self.chunk_size:]
                            
                            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬
                            processing_thread = threading.Thread(
                                target=self.process_audio_chunk,
                                args=(audio_data,),
                                daemon=True
                            )
                            processing_thread.start()
                    
                    time.sleep(0.1)  # CPU ì‚¬ìš©ëŸ‰ ì¡°ì ˆ
                    
                except queue.Empty:
                    continue
                except KeyboardInterrupt:
                    print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
                    break
                except Exception as e:
                    print(f"âŒ ë©”ì¸ ë£¨í”„ ì˜¤ë¥˜: {e}")
                    time.sleep(1)
        
        except Exception as e:
            print(f"âŒ ìš¸ìŒ ê°ì§€ ì‹œì‘ ì‹¤íŒ¨: {e}")
        
        finally:
            self.stop_detection()
    
    def stop_detection(self) -> None:
        """
        ìš¸ìŒ ê°ì§€ ì¤‘ì§€
        """
        print("ğŸ›‘ ìš¸ìŒ ê°ì§€ ì¤‘ì§€ ì¤‘...")
        
        self.is_running = False
        
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None
        
        if self.audio:
            self.audio.terminate()
        
        print("âœ… ìš¸ìŒ ê°ì§€ ì™„ì „íˆ ì¤‘ì§€ë¨")
    
    def test_microphone(self) -> None:
        """
        ë§ˆì´í¬ ì—°ê²° í…ŒìŠ¤íŠ¸
        """
        print("ğŸ¤ ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        try:
            # ì§§ì€ ë…¹ìŒ í…ŒìŠ¤íŠ¸
            test_stream = self.audio.open(
                format=pyaudio.paFloat32,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=1024
            )
            
            print("5ì´ˆ ë™ì•ˆ ì†Œë¦¬ë¥¼ ë‚´ë³´ì„¸ìš”...")
            
            for i in range(50):  # 5ì´ˆê°„ í…ŒìŠ¤íŠ¸
                data = test_stream.read(1024)
                audio_data = np.frombuffer(data, dtype=np.float32)
                volume = np.sqrt(np.mean(audio_data**2))
                
                print(f"\rë³¼ë¥¨ ë ˆë²¨: {'â–ˆ' * int(volume * 50):<50} {volume:.4f}", end='')
                time.sleep(0.1)
            
            test_stream.close()
            print("\nâœ… ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    def cleanup_old_files(self, days_to_keep: int = 7) -> None:
        """
        ì˜¤ë˜ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë¦¬
        
        Args:
            days_to_keep: ë³´ê´€í•  ì¼ìˆ˜
        """
        if not self.save_audio:
            return
        
        try:
            cutoff_time = time.time() - (days_to_keep * 24 * 60 * 60)
            
            for folder in ['detections', 'continuous']:
                folder_path = f"{self.audio_save_path}/{folder}"
                if os.path.exists(folder_path):
                    for filename in os.listdir(folder_path):
                        file_path = os.path.join(folder_path, filename)
                        if os.path.isfile(file_path) and os.path.getctime(file_path) < cutoff_time:
                            os.remove(file_path)
                            print(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ: {filename}")
                            
        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ì•„ê¸° ìš¸ìŒ ê°ì§€ ì‹œìŠ¤í…œ')
    parser.add_argument('--mode', choices=['detect', 'test'], default='detect',
                       help='ì‹¤í–‰ ëª¨ë“œ: detect (ê°ì§€) ë˜ëŠ” test (ë§ˆì´í¬ í…ŒìŠ¤íŠ¸)')
    parser.add_argument('--confidence', type=float, default=0.8,
                       help='ê°ì§€ ì‹ ë¢°ë„ ì„ê³„ê°’ (0.0-1.0)')
    parser.add_argument('--server', type=str, default='http://192.168.0.4:5000',
                       help='Node.js ì„œë²„ URL')
    parser.add_argument('--save-audio', action='store_true',
                       help='ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ í™œì„±í™”')
    parser.add_argument('--sample-rate', type=int, default=16000,
                       help='ì˜¤ë””ì˜¤ ìƒ˜í”Œë§ ë ˆì´íŠ¸ (Hz)')
    parser.add_argument('--chunk-size', type=int, default=8192,
                       help='ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì²­í¬ í¬ê¸°')
    
    args = parser.parse_args()
    
    # ê°ì§€ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    detector = BabyCryDetector(
        confidence_threshold=args.confidence,
        nodejs_server=args.server,
        save_audio=args.save_audio,
        sample_rate=args.sample_rate,
        chunk_size=args.chunk_size
    )
    
    if args.mode == 'test':
        detector.test_microphone()
    else:
        try:
            # ì‹œì‘ ì‹œ ì˜¤ë˜ëœ íŒŒì¼ ì •ë¦¬
            if args.save_audio:
                detector.cleanup_old_files()
            
            detector.start_detection()
        except KeyboardInterrupt:
            print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        finally:
            detector.stop_detection()


if __name__ == "__main__":
    main()